{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "os.chdir(\"/home/william/Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "class Analisis_Predictivo:\n",
    "\n",
    "    def __init__(self,datos, predecir:str, predictoras = [],\n",
    "                 modelo = None,train_size = 80,random_state = None):\n",
    "        '''\n",
    "        datos: Datos completos y listos para construir un modelo\n",
    "\n",
    "        modelo: Instancia de una Clase de un método de clasificación(KNN,Árboles,SVM,etc).\n",
    "        Si no especifica un modelo no podrá utilizar el método fit_n_review()\n",
    "\n",
    "        predecir: Nombre de la variable a predecir\n",
    "\n",
    "        predictoras: Lista de los nombres de las variables predictoras.\n",
    "        Si vacío entonces utiliza todas las variables presentes excepto la variable a predecir.\n",
    "\n",
    "        train_size: Proporción de la tabla de entrenamiento respecto a la original.\n",
    "\n",
    "        random_state: Semilla aleatoria para la división de datos(training-testing).\n",
    "        '''\n",
    "        self.datos = datos\n",
    "        self.predecir = predecir\n",
    "        self.predictoras = predictoras\n",
    "        self.modelo = modelo\n",
    "        self.random_state = random_state\n",
    "        if modelo != None:\n",
    "            self.train_size = train_size\n",
    "            self._training_testing()\n",
    "\n",
    "\n",
    "    def _training_testing(self):\n",
    "        if len(self.predictoras) == 0:\n",
    "            X = self.datos.drop(columns=[self.predecir])\n",
    "        else:\n",
    "            X = self.datos[self.predictoras]\n",
    "\n",
    "        y = self.datos[self.predecir].values\n",
    "\n",
    "        train_test = train_test_split(X, y, train_size=self.train_size,\n",
    "                                      random_state=self.random_state)\n",
    "        self.X_train, self.X_test,self.y_train, self.y_test = train_test\n",
    "\n",
    "\n",
    "    def fit_predict(self):\n",
    "        if self.modelo != None:\n",
    "            self.modelo.fit(self.X_train,self.y_train)\n",
    "            return self.modelo.predict(self.X_test)\n",
    "\n",
    "    def fit_predict_resultados(self, imprimir = True):\n",
    "        if(self.modelo != None):\n",
    "            y = self.datos[self.predecir].values\n",
    "            prediccion = self.fit_predict()\n",
    "            MC = confusion_matrix(self.y_test, prediccion)\n",
    "            indices = self.indices_general(MC,list(np.unique(y)))\n",
    "            if imprimir == True:\n",
    "                for k in indices:\n",
    "                    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n",
    "\n",
    "            return indices\n",
    "\n",
    "    def indices_general(self,MC, nombres = None):\n",
    "        \"Método para calcular los índices de calidad de la predicción\"\n",
    "        precision_global = np.sum(MC.diagonal()) / np.sum(MC)\n",
    "        error_global = 1 - precision_global\n",
    "        precision_categoria  = pd.DataFrame(MC.diagonal()/np.sum(MC,axis = 1)).T\n",
    "        if nombres!=None:\n",
    "            precision_categoria.columns = nombres\n",
    "        return {\"Matriz de Confusión\":MC,\n",
    "                \"Precisión Global\":precision_global,\n",
    "                \"Error Global\":error_global,\n",
    "                \"Precisión por categoría\":precision_categoria}\n",
    "\n",
    "    def distribucion_variable_predecir(self):\n",
    "        \"Método para graficar la distribución de la variable a predecir\"\n",
    "        variable_predict = self.predecir\n",
    "        data = self.datos\n",
    "        colors = list(dict(**mcolors.CSS4_COLORS))\n",
    "        df = pd.crosstab(index=data[variable_predict],columns=\"valor\") / data[variable_predict].count()\n",
    "        fig = plt.figure(figsize=(10,9))\n",
    "        g = fig.add_subplot(111)\n",
    "        countv = 0\n",
    "        titulo = \"Distribución de la variable %s\" % variable_predict\n",
    "        for i in range(df.shape[0]):\n",
    "            g.barh(1,df.iloc[i],left = countv, align='center',color=colors[11+i],label= df.iloc[i].name)\n",
    "            countv = countv + df.iloc[i]\n",
    "        vals = g.get_xticks()\n",
    "        g.set_xlim(0,1)\n",
    "        g.set_yticklabels(\"\")\n",
    "        g.set_title(titulo)\n",
    "        g.set_ylabel(variable_predict)\n",
    "        g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "        countv = 0\n",
    "        for v in df.iloc[:,0]:\n",
    "            g.text(np.mean([countv,countv+v]) - 0.03, 1 , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "            countv = countv + v\n",
    "        g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n",
    "\n",
    "    def poder_predictivo_categorica(self, var:str):\n",
    "        \"Método para ver la distribución de una variable categórica respecto a la predecir\"\n",
    "        data = self.datos\n",
    "        variable_predict = self.predecir\n",
    "        df = pd.crosstab(index= data[var],columns=data[variable_predict])\n",
    "        df = df.div(df.sum(axis=1),axis=0)\n",
    "        titulo = \"Distribución de la variable %s según la variable %s\" % (var,variable_predict)\n",
    "        g = df.plot(kind='barh',stacked=True,legend = True, figsize = (10,9), \\\n",
    "                    xlim = (0,1),title = titulo, width = 0.8)\n",
    "        vals = g.get_xticks()\n",
    "        g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "        g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n",
    "        for bars in g.containers:\n",
    "            plt.setp(bars, width=.9)\n",
    "        for i in range(df.shape[0]):\n",
    "            countv = 0\n",
    "            for v in df.iloc[i]:\n",
    "                g.text(np.mean([countv,countv+v]) - 0.03, i , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "                countv = countv + v\n",
    "\n",
    "\n",
    "    def poder_predictivo_numerica(self,var:str):\n",
    "        \"Función para ver la distribución de una variable numérica respecto a la predecir\"\n",
    "        sns.FacetGrid(self.datos, hue=self.predecir, height=6).map(sns.kdeplot, var, shade=True).add_legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "def transformToDataFrame(modelo):\n",
    "    resultados = modelo.fit_predict_resultados(imprimir=True)\n",
    "    precisionGlobal = pd.DataFrame({\"Precisión Global\" : [resultados['Precisión Global']]})\n",
    "    errorGlobal = pd.DataFrame({\"Error Global\" : [resultados['Error Global']]})\n",
    "    precisonCategoria = resultados['Precisión por categoría']\n",
    "    finalDataFrame = precisionGlobal.join(errorGlobal).join(precisonCategoria)\n",
    "    return finalDataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "potabilidad = pd.read_csv(\"potabilidad_V2.csv\")\n",
    "potabilidad = potabilidad.iloc[:,1:]\n",
    "potabilidad[\"Potability\"] = potabilidad[\"Potability\"].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El primer modelo sin estandarizar los datos  muestra unos resultados bastante malos, por que como podemos ver en el dataframe de abajo, aunque tiene una precision global interesante, la verdadera metrica, se ve en el \"NO\" y el \"SI\", y podemos ver que el valor de si es muy bajo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[257  52]\n",
      " [161  33]]\n",
      "\n",
      "Precisión Global:\n",
      "0.5765407554671969\n",
      "\n",
      "Error Global:\n",
      "0.42345924453280315\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.831715  0.170103\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.576541      0.423459  0.831715  0.170103",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.576541</td>\n      <td>0.423459</td>\n      <td>0.831715</td>\n      <td>0.170103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(potabilidad,predecir= \"Potability\",modelo=modelo,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que el primer modelo sin estandarizar los datos muestra unos resultados pesimos, el segundo modelo muestra unos resultados aun peores que el anterior, aunque parece que predice bien el \"no\", esto no es cierto por que al ver el valor del \"SI\",  podemos que lo que sucede es que categoriza casi todo como \"NO\", entonces por eso tiene ese valor tan alto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[309   0]\n",
      " [192   2]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6182902584493042\n",
      "\n",
      "Error Global:\n",
      "0.3817097415506958\n",
      "\n",
      "Precisión por categoría:\n",
      "    No        Si\n",
      "0  1.0  0.010309\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global   No        Si\n0           0.61829       0.38171  1.0  0.010309",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.61829</td>\n      <td>0.38171</td>\n      <td>1.0</td>\n      <td>0.010309</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(potabilidad,predecir= \"Potability\",modelo=modelo2,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "potabilidad.iloc[:,:-1] = StandardScaler().fit_transform(potabilidad.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estas metricas pertenecen al modelo 1, con la estandarizacion de datos y aunque los resultados son malo al igual que en el anterior de acuerdo a la matriz de confusion podemos darnos cuenta, que realmente si mejoran bastante, con respecto al anterior"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[304   5]\n",
      " [184  10]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6242544731610338\n",
      "\n",
      "Error Global:\n",
      "0.3757455268389662\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.983819  0.051546\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.624254      0.375746  0.983819  0.051546",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.624254</td>\n      <td>0.375746</td>\n      <td>0.983819</td>\n      <td>0.051546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(potabilidad,predecir= \"Potability\",modelo=modelo,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "\n",
    "transformToDataFrame(analisisModelo1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el caso del modelo 2 podemos ver que se mejora en el tema del si, aunque claramente se puede notar que es muy poco, si nota que la estadarizacion de datos es demasiado importante cuando estamos usando las redes neuronales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[306   3]\n",
      " [192   2]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6123260437375746\n",
      "\n",
      "Error Global:\n",
      "0.3876739562624254\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.990291  0.010309\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.612326      0.387674  0.990291  0.010309",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.612326</td>\n      <td>0.387674</td>\n      <td>0.990291</td>\n      <td>0.010309</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(potabilidad,predecir= \"Potability\",modelo=modelo2,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}