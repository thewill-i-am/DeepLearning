{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from operator import itemgetter\n",
    "\n",
    "os.chdir(\"/home/william/Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class Analisis_Predictivo:\n",
    "\n",
    "    def __init__(self, predecir=None, predictoras = [],\n",
    "                 modelo = None,train_size = None,random_state = None,\n",
    "                 xtrain=None, ytrain=None, xtest=None, ytest=None,datos = None):\n",
    "        '''\n",
    "        datos: Datos completos y listos para construir un modelo\n",
    "\n",
    "        modelo: Instancia de una Clase de un método de clasificación(KNN,Árboles,SVM,etc).\n",
    "        Si no especifica un modelo no podrá utilizar el método fit_n_review()\n",
    "\n",
    "        predecir: Nombre de la variable a predecir\n",
    "\n",
    "        predictoras: Lista de los nombres de las variables predictoras.\n",
    "        Si vacío entonces utiliza todas las variables presentes excepto la variable a predecir.\n",
    "\n",
    "        train_size: Proporción de la tabla de entrenamiento respecto a la original.\n",
    "\n",
    "        random_state: Semilla aleatoria para la división de datos(training-testing).\n",
    "        '''\n",
    "        self.datos = datos\n",
    "        self.predecir = predecir\n",
    "        self.predictoras = predictoras\n",
    "        self.modelo = modelo\n",
    "        self.random_state = random_state\n",
    "        self.X_train = xtrain\n",
    "        self.X_test = xtest\n",
    "        self.y_train = ytrain\n",
    "        self.y_test = ytest\n",
    "        if modelo != None and train_size != None:\n",
    "            self.train_size = train_size\n",
    "            self._training_testing()\n",
    "\n",
    "\n",
    "    def _training_testing(self):\n",
    "        if len(self.predictoras) == 0:\n",
    "            X = self.datos.drop(columns=[self.predecir])\n",
    "        else:\n",
    "            X = self.datos[self.predictoras]\n",
    "\n",
    "        y = self.datos[self.predecir].values\n",
    "\n",
    "        train_test = train_test_split(X, y, train_size=self.train_size,\n",
    "                                      random_state=self.random_state)\n",
    "        self.X_train, self.X_test,self.y_train, self.y_test = train_test\n",
    "\n",
    "\n",
    "    def fit_predict(self):\n",
    "        if self.modelo != None:\n",
    "            self.modelo.fit(self.X_train,self.y_train)\n",
    "            return self.modelo.predict(self.X_test)\n",
    "\n",
    "    def fit_predict_resultados(self, imprimir = True, inyectado=None, custom=False):\n",
    "        if(self.modelo != None):\n",
    "            if custom == False:\n",
    "                y = self.datos[self.predecir].values\n",
    "            else:\n",
    "                y= inyectado\n",
    "            prediccion = self.fit_predict()\n",
    "            MC = confusion_matrix(self.y_test, prediccion)\n",
    "            indices = self.indices_general(MC,list(np.unique(y)))\n",
    "            if imprimir == True:\n",
    "                for k in indices:\n",
    "                    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n",
    "\n",
    "            return indices\n",
    "\n",
    "    def indices_general(self,MC, nombres = None):\n",
    "        \"Método para calcular los índices de calidad de la predicción\"\n",
    "        precision_global = np.sum(MC.diagonal()) / np.sum(MC)\n",
    "        error_global = 1 - precision_global\n",
    "        precision_categoria  = pd.DataFrame(MC.diagonal()/np.sum(MC,axis = 1)).T\n",
    "        if nombres!=None:\n",
    "            precision_categoria.columns = nombres\n",
    "        return {\"Matriz de Confusión\":MC,\n",
    "                \"Precisión Global\":precision_global,\n",
    "                \"Error Global\":error_global,\n",
    "                \"Precisión por categoría\":precision_categoria}\n",
    "\n",
    "    def distribucion_variable_predecir(self):\n",
    "        \"Método para graficar la distribución de la variable a predecir\"\n",
    "        variable_predict = self.predecir\n",
    "        data = self.datos\n",
    "        colors = list(dict(**mcolors.CSS4_COLORS))\n",
    "        df = pd.crosstab(index=data[variable_predict],columns=\"valor\") / data[variable_predict].count()\n",
    "        fig = plt.figure(figsize=(10,9))\n",
    "        g = fig.add_subplot(111)\n",
    "        countv = 0\n",
    "        titulo = \"Distribución de la variable %s\" % variable_predict\n",
    "        for i in range(df.shape[0]):\n",
    "            g.barh(1,df.iloc[i],left = countv, align='center',color=colors[11+i],label= df.iloc[i].name)\n",
    "            countv = countv + df.iloc[i]\n",
    "        vals = g.get_xticks()\n",
    "        g.set_xlim(0,1)\n",
    "        g.set_yticklabels(\"\")\n",
    "        g.set_title(titulo)\n",
    "        g.set_ylabel(variable_predict)\n",
    "        g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "        countv = 0\n",
    "        for v in df.iloc[:,0]:\n",
    "            g.text(np.mean([countv,countv+v]) - 0.03, 1 , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "            countv = countv + v\n",
    "        g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n",
    "\n",
    "    def poder_predictivo_categorica(self, var:str):\n",
    "        \"Método para ver la distribución de una variable categórica respecto a la predecir\"\n",
    "        data = self.datos\n",
    "        variable_predict = self.predecir\n",
    "        df = pd.crosstab(index= data[var],columns=data[variable_predict])\n",
    "        df = df.div(df.sum(axis=1),axis=0)\n",
    "        titulo = \"Distribución de la variable %s según la variable %s\" % (var,variable_predict)\n",
    "        g = df.plot(kind='barh',stacked=True,legend = True, figsize = (10,9), \\\n",
    "                    xlim = (0,1),title = titulo, width = 0.8)\n",
    "        vals = g.get_xticks()\n",
    "        g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "        g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n",
    "        for bars in g.containers:\n",
    "            plt.setp(bars, width=.9)\n",
    "        for i in range(df.shape[0]):\n",
    "            countv = 0\n",
    "            for v in df.iloc[i]:\n",
    "                g.text(np.mean([countv,countv+v]) - 0.03, i , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "                countv = countv + v\n",
    "\n",
    "\n",
    "    def poder_predictivo_numerica(self,var:str):\n",
    "        \"Función para ver la distribución de una variable numérica respecto a la predecir\"\n",
    "        sns.FacetGrid(self.datos, hue=self.predecir, height=6).map(sns.kdeplot, var, shade=True).add_legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def transformToDataFrame(modelo):\n",
    "    resultados = modelo.fit_predict_resultados(imprimir=True)\n",
    "    precisionGlobal = pd.DataFrame({\"Precisión Global\" : [resultados['Precisión Global']]})\n",
    "    errorGlobal = pd.DataFrame({\"Error Global\" : [resultados['Error Global']]})\n",
    "    precisonCategoria = resultados['Precisión por categoría']\n",
    "    finalDataFrame = precisionGlobal.join(errorGlobal).join(precisonCategoria)\n",
    "    return finalDataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "potabilidad = pd.read_csv(\"potabilidad_V2.csv\")\n",
    "potabilidad = potabilidad.iloc[:,1:]\n",
    "potabilidad[\"Potability\"] = potabilidad[\"Potability\"].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El primer modelo sin estandarizar los datos  muestra unos resultados bastante malos, por que como podemos ver en el dataframe de abajo, aunque tiene una precision global interesante, la verdadera metrica, se ve en el \"NO\" y el \"SI\", y podemos ver que el valor de si es muy bajo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[257  52]\n",
      " [161  33]]\n",
      "\n",
      "Precisión Global:\n",
      "0.5765407554671969\n",
      "\n",
      "Error Global:\n",
      "0.42345924453280315\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.831715  0.170103\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.576541      0.423459  0.831715  0.170103",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.576541</td>\n      <td>0.423459</td>\n      <td>0.831715</td>\n      <td>0.170103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(datos=potabilidad,predecir=\"Potability\",modelo=modelo,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que el primer modelo sin estandarizar los datos muestra unos resultados pesimos, el segundo modelo muestra unos resultados aun peores que el anterior, aunque parece que predice bien el \"no\", esto no es cierto por que al ver el valor del \"SI\",  podemos que lo que sucede es que categoriza casi todo como \"NO\", entonces por eso tiene ese valor tan alto"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[309   0]\n",
      " [192   2]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6182902584493042\n",
      "\n",
      "Error Global:\n",
      "0.3817097415506958\n",
      "\n",
      "Precisión por categoría:\n",
      "    No        Si\n",
      "0  1.0  0.010309\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global   No        Si\n0           0.61829       0.38171  1.0  0.010309",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.61829</td>\n      <td>0.38171</td>\n      <td>1.0</td>\n      <td>0.010309</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(datos=potabilidad,predecir= \"Potability\",modelo=modelo2,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "potabilidad.iloc[:,:-1] = StandardScaler().fit_transform(potabilidad.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estas metricas pertenecen al modelo 1, con la estandarizacion de datos y aunque los resultados son malo al igual que en el anterior de acuerdo a la matriz de confusion podemos darnos cuenta, que realmente si mejoran bastante, con respecto al anterior"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[304   5]\n",
      " [184  10]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6242544731610338\n",
      "\n",
      "Error Global:\n",
      "0.3757455268389662\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.983819  0.051546\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.624254      0.375746  0.983819  0.051546",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.624254</td>\n      <td>0.375746</td>\n      <td>0.983819</td>\n      <td>0.051546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(datos=potabilidad,predecir= \"Potability\",modelo=modelo,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "\n",
    "transformToDataFrame(analisisModelo1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el caso del modelo 2 podemos ver que se mejora en el tema del si, aunque claramente se puede notar que es muy poco, si nota que la estadarizacion de datos es demasiado importante cuando estamos usando las redes neuronales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[306   3]\n",
      " [192   2]]\n",
      "\n",
      "Precisión Global:\n",
      "0.6123260437375746\n",
      "\n",
      "Error Global:\n",
      "0.3876739562624254\n",
      "\n",
      "Precisión por categoría:\n",
      "         No        Si\n",
      "0  0.990291  0.010309\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global        No        Si\n0          0.612326      0.387674  0.990291  0.010309",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>No</th>\n      <th>Si</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.612326</td>\n      <td>0.387674</td>\n      <td>0.990291</td>\n      <td>0.010309</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(datos=potabilidad,predecir= \"Potability\",modelo=modelo2,\n",
    "                                       train_size= 0.75, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "      volatil.acidez  citrica.acidez  residual.azucar  cloruros  \\\n0               0.30            0.21              1.1     0.032   \n1               0.61            0.01              1.9     0.080   \n2               0.32            0.23             16.2     0.055   \n3               0.22            0.29              8.9     0.050   \n4               0.43            0.27              1.1     0.054   \n...              ...             ...              ...       ...   \n6492            0.24            0.19              1.2     0.041   \n6493            0.26            0.43             12.6     0.033   \n6494            0.25            0.48             10.0     0.044   \n6495            0.60            0.20              9.9     0.070   \n6496            0.39            0.16              1.4     0.080   \n\n      libre.sulfuro.dioxido  total.sulfuro.dioxido  densidad    pH  sulfitos  \\\n0                      31.0                  111.0   0.98890  2.97      0.42   \n1                       8.0                   25.0   0.99746  3.69      0.73   \n2                      36.0                  176.0   0.99860  3.26      0.54   \n3                      24.0                   90.0   0.99556  3.29      0.46   \n4                       5.0                  110.0   0.99390  3.24      0.52   \n...                     ...                    ...       ...   ...       ...   \n6492                   30.0                  111.0   0.99254  2.99      0.46   \n6493                   64.0                  230.0   0.99740  3.08      0.38   \n6494                   78.0                  240.0   0.99655  3.25      0.47   \n6495                   21.0                  174.0   0.99710  3.03      0.54   \n6496                   11.0                   23.0   0.99550  3.34      0.56   \n\n      alcohol  calidad    tipo  \n0        12.2        6  blanco  \n1        10.5        5   tinto  \n2         9.1        5  blanco  \n3         9.8        6  blanco  \n4         9.1        4  blanco  \n...       ...      ...     ...  \n6492      9.4        6  blanco  \n6493      8.9        5  blanco  \n6494      9.5        6  blanco  \n6495      9.1        5  blanco  \n6496      9.3        5   tinto  \n\n[6497 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>volatil.acidez</th>\n      <th>citrica.acidez</th>\n      <th>residual.azucar</th>\n      <th>cloruros</th>\n      <th>libre.sulfuro.dioxido</th>\n      <th>total.sulfuro.dioxido</th>\n      <th>densidad</th>\n      <th>pH</th>\n      <th>sulfitos</th>\n      <th>alcohol</th>\n      <th>calidad</th>\n      <th>tipo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.30</td>\n      <td>0.21</td>\n      <td>1.1</td>\n      <td>0.032</td>\n      <td>31.0</td>\n      <td>111.0</td>\n      <td>0.98890</td>\n      <td>2.97</td>\n      <td>0.42</td>\n      <td>12.2</td>\n      <td>6</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.61</td>\n      <td>0.01</td>\n      <td>1.9</td>\n      <td>0.080</td>\n      <td>8.0</td>\n      <td>25.0</td>\n      <td>0.99746</td>\n      <td>3.69</td>\n      <td>0.73</td>\n      <td>10.5</td>\n      <td>5</td>\n      <td>tinto</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.32</td>\n      <td>0.23</td>\n      <td>16.2</td>\n      <td>0.055</td>\n      <td>36.0</td>\n      <td>176.0</td>\n      <td>0.99860</td>\n      <td>3.26</td>\n      <td>0.54</td>\n      <td>9.1</td>\n      <td>5</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.22</td>\n      <td>0.29</td>\n      <td>8.9</td>\n      <td>0.050</td>\n      <td>24.0</td>\n      <td>90.0</td>\n      <td>0.99556</td>\n      <td>3.29</td>\n      <td>0.46</td>\n      <td>9.8</td>\n      <td>6</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.43</td>\n      <td>0.27</td>\n      <td>1.1</td>\n      <td>0.054</td>\n      <td>5.0</td>\n      <td>110.0</td>\n      <td>0.99390</td>\n      <td>3.24</td>\n      <td>0.52</td>\n      <td>9.1</td>\n      <td>4</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6492</th>\n      <td>0.24</td>\n      <td>0.19</td>\n      <td>1.2</td>\n      <td>0.041</td>\n      <td>30.0</td>\n      <td>111.0</td>\n      <td>0.99254</td>\n      <td>2.99</td>\n      <td>0.46</td>\n      <td>9.4</td>\n      <td>6</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>6493</th>\n      <td>0.26</td>\n      <td>0.43</td>\n      <td>12.6</td>\n      <td>0.033</td>\n      <td>64.0</td>\n      <td>230.0</td>\n      <td>0.99740</td>\n      <td>3.08</td>\n      <td>0.38</td>\n      <td>8.9</td>\n      <td>5</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>6494</th>\n      <td>0.25</td>\n      <td>0.48</td>\n      <td>10.0</td>\n      <td>0.044</td>\n      <td>78.0</td>\n      <td>240.0</td>\n      <td>0.99655</td>\n      <td>3.25</td>\n      <td>0.47</td>\n      <td>9.5</td>\n      <td>6</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>6495</th>\n      <td>0.60</td>\n      <td>0.20</td>\n      <td>9.9</td>\n      <td>0.070</td>\n      <td>21.0</td>\n      <td>174.0</td>\n      <td>0.99710</td>\n      <td>3.03</td>\n      <td>0.54</td>\n      <td>9.1</td>\n      <td>5</td>\n      <td>blanco</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>0.39</td>\n      <td>0.16</td>\n      <td>1.4</td>\n      <td>0.080</td>\n      <td>11.0</td>\n      <td>23.0</td>\n      <td>0.99550</td>\n      <td>3.34</td>\n      <td>0.56</td>\n      <td>9.3</td>\n      <td>5</td>\n      <td>tinto</td>\n    </tr>\n  </tbody>\n</table>\n<p>6497 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"wine.csv\")\n",
    "wine = wine.iloc[:,1:]\n",
    "wine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el primer modelo , la tabla de vinos nos envia unos resultados sorprendentes, podemos ver que aun sin estandarizacion tenemos un resultado del 97% en la precision global, pero igualmente se puede ver en los valores especificos de si es tinto o blanco, podemos ver que es super alto, lo que a su vez indica que el error global es muy bajo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[965  12]\n",
      " [ 18 305]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9769230769230769\n",
      "\n",
      "Error Global:\n",
      "0.023076923076923106\n",
      "\n",
      "Precisión por categoría:\n",
      "     blanco     tinto\n",
      "0  0.987718  0.944272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/PycharmProjects/pythonProject/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global    blanco     tinto\n0          0.976923      0.023077  0.987718  0.944272",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>blanco</th>\n      <th>tinto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.976923</td>\n      <td>0.023077</td>\n      <td>0.987718</td>\n      <td>0.944272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(datos=wine,predecir= \"tipo\",modelo=modelo,\n",
    "                                       train_size= 0.80, random_state=0)\n",
    "transformToDataFrame(analisisModelo1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el segundo modelo , la tabla de vinos nos envia unos resultados sorprendentes, podemos ver que aun sin estandarizacion tenemos un resultado del 92% en la precision global, pero igualmente se puede ver en los valores especificos de si es tinto o blanco, podemos ver que es super alto, lo que a su vez indica que el error global es muy bajo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[936  41]\n",
      " [ 59 264]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9230769230769231\n",
      "\n",
      "Error Global:\n",
      "0.07692307692307687\n",
      "\n",
      "Precisión por categoría:\n",
      "     blanco     tinto\n",
      "0  0.958035  0.817337\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global    blanco     tinto\n0          0.923077      0.076923  0.958035  0.817337",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>blanco</th>\n      <th>tinto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.923077</td>\n      <td>0.076923</td>\n      <td>0.958035</td>\n      <td>0.817337</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(datos=wine,predecir= \"tipo\",modelo=modelo2,\n",
    "                                       train_size= 0.80, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "wine.iloc[:,:-1] = StandardScaler().fit_transform(wine.iloc[:,:-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En el caso de cuando es estandarizado, lo que sucede es que mejora bastante con respecto al modelo sin estandarizar, que de igualmanera era bastante alta, pero ahora esta espectacular"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[974   3]\n",
      " [  4 319]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9946153846153846\n",
      "\n",
      "Error Global:\n",
      "0.005384615384615432\n",
      "\n",
      "Precisión por categoría:\n",
      "     blanco     tinto\n",
      "0  0.996929  0.987616\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global    blanco     tinto\n0          0.994615      0.005385  0.996929  0.987616",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>blanco</th>\n      <th>tinto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.994615</td>\n      <td>0.005385</td>\n      <td>0.996929</td>\n      <td>0.987616</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MLPClassifier(hidden_layer_sizes= (6,) , activation= \"identity\", solver=\"adam\", random_state=0)\n",
    "analisisModelo1 = Analisis_Predictivo(datos=wine,predecir= \"tipo\",modelo=modelo,\n",
    "                                       train_size= 0.80, random_state=0)\n",
    "\n",
    "transformToDataFrame(analisisModelo1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "De igualmanera para el modelo 2 estandarizado, aunque el modelo 2 sin estandarizar fue bueno con un 92%, este modelo lo supera por mucho."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realmente la conclusion que me dejo este ejercicio es que siempre en las redes neuronales se obtiene un mejor resultado cuando se realiza la estandarizacion de datos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[974   3]\n",
      " [  5 318]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9938461538461538\n",
      "\n",
      "Error Global:\n",
      "0.006153846153846176\n",
      "\n",
      "Precisión por categoría:\n",
      "     blanco    tinto\n",
      "0  0.996929  0.98452\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Precisión Global  Error Global    blanco    tinto\n0          0.993846      0.006154  0.996929  0.98452",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precisión Global</th>\n      <th>Error Global</th>\n      <th>blanco</th>\n      <th>tinto</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.993846</td>\n      <td>0.006154</td>\n      <td>0.996929</td>\n      <td>0.98452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = MLPClassifier(hidden_layer_sizes= (10,25) , activation=\"tanh\", solver=\"sgd\", random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(datos=wine,predecir= \"tipo\",modelo=modelo2,\n",
    "                                      train_size= 0.80, random_state=0)\n",
    "transformToDataFrame(analisisModelo2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "dataTest = pd.read_csv(\"ZipDataTestCod.csv\", sep=\";\")\n",
    "dataTrain = pd.read_csv(\"ZipDataTrainCod.csv\", sep=\";\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def comprimir(data, p=4, filtradoPorMayor = False):\n",
    "  t = pd.DataFrame()\n",
    "\n",
    "  for k in range(len(data)):\n",
    "    matriz = data.iloc[k]\n",
    "    matriz = np.array([matriz]).reshape(16,16)\n",
    "    inicial_espe = 0\n",
    "    fin_espe = p\n",
    "    contador = 0\n",
    "    datos = []\n",
    "\n",
    "    for i in range(p):\n",
    "      inicial = 0\n",
    "      fin = p\n",
    "\n",
    "      for j in range(p):\n",
    "        mayor = matriz[inicial_espe:fin_espe, inicial:fin]\n",
    "        num = max(map(max, mayor))\n",
    "\n",
    "        if not filtradoPorMayor:\n",
    "            datos.append(sum(sum(matriz[inicial_espe:fin_espe, inicial:fin]))/(p*p))\n",
    "        else:\n",
    "            datos.append(num)\n",
    "\n",
    "        contador += 1\n",
    "        inicial += p\n",
    "        fin += p\n",
    "\n",
    "      inicial_espe += p\n",
    "      fin_espe += p\n",
    "\n",
    "    t.loc[:,k] = datos\n",
    "\n",
    "  return t.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "ytest = dataTest['Numero']\n",
    "dataTest = dataTest.drop(columns=['Numero'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "ytrain = dataTrain['Numero']\n",
    "dataTrain = dataTrain.drop(columns=['Numero'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[352   0   3   2   1   0   1   0   0   0]\n",
      " [  3 147   0   1   3   1   0   0   5   0]\n",
      " [  1   2 187   2   4   0   2   0   0   2]\n",
      " [  3   0   2 181   0   6   1   2   3   0]\n",
      " [  0   1   6   0 169   0   0   1   0   0]\n",
      " [  4   1   3   2   1 150   0   1   4   0]\n",
      " [  0   1   2   3   0   1 163   0   0   0]\n",
      " [  0   0   7   1   2   1   0 136   0   0]\n",
      " [  1   9   0   3   0   4   0   0 149   0]\n",
      " [  0   0   4   1   1   1   3   0   1 253]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9402092675635276\n",
      "\n",
      "Error Global:\n",
      "0.05979073243647237\n",
      "\n",
      "Precisión por categoría:\n",
      "       cero    cinco  cuatro       dos     nueve      ocho      seis    siete  \\\n",
      "0  0.980501  0.91875   0.935  0.914141  0.954802  0.903614  0.958824  0.92517   \n",
      "\n",
      "      tres       uno  \n",
      "0  0.89759  0.958333  \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Matriz de Confusión': array([[352,   0,   3,   2,   1,   0,   1,   0,   0,   0],\n        [  3, 147,   0,   1,   3,   1,   0,   0,   5,   0],\n        [  1,   2, 187,   2,   4,   0,   2,   0,   0,   2],\n        [  3,   0,   2, 181,   0,   6,   1,   2,   3,   0],\n        [  0,   1,   6,   0, 169,   0,   0,   1,   0,   0],\n        [  4,   1,   3,   2,   1, 150,   0,   1,   4,   0],\n        [  0,   1,   2,   3,   0,   1, 163,   0,   0,   0],\n        [  0,   0,   7,   1,   2,   1,   0, 136,   0,   0],\n        [  1,   9,   0,   3,   0,   4,   0,   0, 149,   0],\n        [  0,   0,   4,   1,   1,   1,   3,   0,   1, 253]]),\n 'Precisión Global': 0.9402092675635276,\n 'Error Global': 0.05979073243647237,\n 'Precisión por categoría':        cero    cinco  cuatro       dos     nueve      ocho      seis    siete  \\\n 0  0.980501  0.91875   0.935  0.914141  0.954802  0.903614  0.958824  0.92517   \n \n       tres       uno  \n 0  0.89759  0.958333  }"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloDataSinComprimir = MLPClassifier(hidden_layer_sizes =(250,100,50,25), max_iter = 50000, activation = 'relu', solver = 'adam',random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(predecir= \"Numero\",modelo=modeloDataSinComprimir, random_state=0, xtrain= dataTrain, xtest=dataTest, ytrain=ytrain, ytest=ytest)\n",
    "analisisModelo2.fit_predict_resultados(inyectado=ytrain.append(ytest), custom=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "       V2   V3   V4     V5     V6     V7     V8     V9    V10    V11  ...  \\\n0    -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -0.631  0.862 -0.167  ...   \n1    -1.0 -1.0 -1.0 -0.813 -0.671 -0.809 -0.887 -0.671 -0.853 -1.000  ...   \n2    -1.0 -1.0 -1.0 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.996  ...   \n3    -1.0 -1.0 -1.0 -1.000 -1.000 -0.273  0.684  0.960  0.450 -0.067  ...   \n4    -1.0 -1.0 -1.0 -1.000 -1.000 -0.928 -0.204  0.751  0.466  0.234  ...   \n...   ...  ...  ...    ...    ...    ...    ...    ...    ...    ...  ...   \n7286 -1.0 -1.0 -1.0 -0.988 -0.527 -0.208  0.620  1.000  0.467  0.396  ...   \n7287 -1.0 -1.0 -1.0 -0.990  0.708  0.557  0.347 -0.107 -0.758 -0.975  ...   \n7288 -1.0 -1.0 -1.0 -0.783 -0.984 -0.827  0.068  1.000  1.000  1.000  ...   \n7289 -1.0 -1.0 -1.0 -1.000 -1.000 -0.549  0.463  0.999  0.999  0.999  ...   \n7290 -1.0 -1.0 -1.0 -1.000 -1.000 -0.108  1.000  0.616 -0.867 -1.000  ...   \n\n       V248   V249   V250   V251   V252   V253   V254   V255   V256  V257  \n0     0.304  0.823  1.000  0.482 -0.474 -0.991 -1.000 -1.000 -1.000  -1.0  \n1    -0.671 -0.671 -0.033  0.761  0.762  0.126 -0.095 -0.671 -0.828  -1.0  \n2    -1.000 -1.000 -1.000 -0.109  1.000 -0.179 -1.000 -1.000 -1.000  -1.0  \n3    -0.318  1.000  0.536 -0.987 -1.000 -1.000 -1.000 -1.000 -1.000  -1.0  \n4     0.466  0.639  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.000  -1.0  \n...     ...    ...    ...    ...    ...    ...    ...    ...    ...   ...  \n7286 -0.116  0.899  0.416 -0.510 -1.000 -1.000 -1.000 -1.000 -1.000  -1.0  \n7287  0.697  0.636  0.167 -0.968 -1.000 -1.000 -1.000 -1.000 -1.000  -1.0  \n7288  0.805  1.000  1.000  0.727 -0.342 -0.933 -1.000 -1.000 -1.000  -1.0  \n7289 -0.231  0.621  0.999 -0.042 -0.231 -0.687 -1.000 -1.000 -1.000  -1.0  \n7290 -0.634  0.803  0.589 -0.907 -1.000 -1.000 -1.000 -1.000 -1.000  -1.0  \n\n[7291 rows x 256 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>...</th>\n      <th>V248</th>\n      <th>V249</th>\n      <th>V250</th>\n      <th>V251</th>\n      <th>V252</th>\n      <th>V253</th>\n      <th>V254</th>\n      <th>V255</th>\n      <th>V256</th>\n      <th>V257</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.631</td>\n      <td>0.862</td>\n      <td>-0.167</td>\n      <td>...</td>\n      <td>0.304</td>\n      <td>0.823</td>\n      <td>1.000</td>\n      <td>0.482</td>\n      <td>-0.474</td>\n      <td>-0.991</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.813</td>\n      <td>-0.671</td>\n      <td>-0.809</td>\n      <td>-0.887</td>\n      <td>-0.671</td>\n      <td>-0.853</td>\n      <td>-1.000</td>\n      <td>...</td>\n      <td>-0.671</td>\n      <td>-0.671</td>\n      <td>-0.033</td>\n      <td>0.761</td>\n      <td>0.762</td>\n      <td>0.126</td>\n      <td>-0.095</td>\n      <td>-0.671</td>\n      <td>-0.828</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.996</td>\n      <td>...</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.109</td>\n      <td>1.000</td>\n      <td>-0.179</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.273</td>\n      <td>0.684</td>\n      <td>0.960</td>\n      <td>0.450</td>\n      <td>-0.067</td>\n      <td>...</td>\n      <td>-0.318</td>\n      <td>1.000</td>\n      <td>0.536</td>\n      <td>-0.987</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.928</td>\n      <td>-0.204</td>\n      <td>0.751</td>\n      <td>0.466</td>\n      <td>0.234</td>\n      <td>...</td>\n      <td>0.466</td>\n      <td>0.639</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.791</td>\n      <td>0.439</td>\n      <td>-0.199</td>\n      <td>-0.883</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7286</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.988</td>\n      <td>-0.527</td>\n      <td>-0.208</td>\n      <td>0.620</td>\n      <td>1.000</td>\n      <td>0.467</td>\n      <td>0.396</td>\n      <td>...</td>\n      <td>-0.116</td>\n      <td>0.899</td>\n      <td>0.416</td>\n      <td>-0.510</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7287</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.990</td>\n      <td>0.708</td>\n      <td>0.557</td>\n      <td>0.347</td>\n      <td>-0.107</td>\n      <td>-0.758</td>\n      <td>-0.975</td>\n      <td>...</td>\n      <td>0.697</td>\n      <td>0.636</td>\n      <td>0.167</td>\n      <td>-0.968</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7288</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.783</td>\n      <td>-0.984</td>\n      <td>-0.827</td>\n      <td>0.068</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>...</td>\n      <td>0.805</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.727</td>\n      <td>-0.342</td>\n      <td>-0.933</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7289</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.549</td>\n      <td>0.463</td>\n      <td>0.999</td>\n      <td>0.999</td>\n      <td>0.999</td>\n      <td>...</td>\n      <td>-0.231</td>\n      <td>0.621</td>\n      <td>0.999</td>\n      <td>-0.042</td>\n      <td>-0.231</td>\n      <td>-0.687</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7290</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.108</td>\n      <td>1.000</td>\n      <td>0.616</td>\n      <td>-0.867</td>\n      <td>-1.000</td>\n      <td>...</td>\n      <td>-0.634</td>\n      <td>0.803</td>\n      <td>0.589</td>\n      <td>-0.907</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7291 rows × 256 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5         6   \\\n0    -1.000000 -0.474625 -0.375937 -1.000000 -0.821563  0.193125 -0.717812   \n1    -0.859687  0.531687  0.310500 -0.038938 -0.833000  0.475688  0.214625   \n2    -1.000000 -0.987500 -0.138437 -0.937500 -0.733625 -0.354875  0.047500   \n3    -0.869625  0.109812  0.074313 -0.647687 -0.667375 -0.701562 -0.093875   \n4    -1.000000  0.025062  0.063687 -1.000000 -1.000000 -0.238062  0.320750   \n...        ...       ...       ...       ...       ...       ...       ...   \n7286 -0.854437  0.637375  0.357000 -0.967375 -1.000000 -0.767750  0.365125   \n7287 -0.981437  0.179000 -0.028625 -1.000000 -1.000000 -0.686937  0.449500   \n7288 -0.512062  0.561813  0.824500 -0.637750 -0.980313 -0.647375  0.697625   \n7289 -0.897938  0.652687  0.769000 -0.689937  0.051688  0.787000  0.502938   \n7290 -1.000000  0.197563 -0.247125 -1.000000 -1.000000  0.300187  0.317125   \n\n            7         8         9         10        11        12        13  \\\n0    -0.804562 -0.008250 -0.009562  0.027188 -0.051063 -0.576125  0.692063   \n1    -0.871188 -0.000250 -0.895750 -0.811813  0.244750 -0.182938  0.228562   \n2    -0.998563 -0.616125  0.111375  0.332375 -0.601938 -1.000000 -0.900688   \n3    -0.848375 -1.000000 -0.911438 -0.075312 -1.000000 -1.000000 -0.403062   \n4    -0.984812 -0.895563 -0.882187 -0.735687 -0.188812 -0.203000  0.169000   \n...        ...       ...       ...       ...       ...       ...       ...   \n7286 -0.996875 -0.955375 -0.309562  0.132625 -0.757437 -0.880563  0.320063   \n7287 -1.000000 -1.000000 -0.681312  0.398062 -0.960938 -0.992063  0.413250   \n7288 -0.761813 -0.863438 -0.600250  0.155438 -0.295813 -0.785125  0.599250   \n7289  0.386000  0.496375  0.126250 -0.066937  0.603812 -0.626812  0.627125   \n7290 -1.000000 -1.000000  0.378625  0.213813 -1.000000 -1.000000 -0.011938   \n\n            14        15  \n0     0.627938 -0.785875  \n1     0.386750  0.313188  \n2     0.170063 -1.000000  \n3    -0.557000 -1.000000  \n4     0.037375 -0.145812  \n...        ...       ...  \n7286  0.131625 -0.976750  \n7287 -0.019063 -1.000000  \n7288  0.676125 -0.832250  \n7289  0.731625 -0.330000  \n7290 -0.309188 -1.000000  \n\n[7291 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.000000</td>\n      <td>-0.474625</td>\n      <td>-0.375937</td>\n      <td>-1.000000</td>\n      <td>-0.821563</td>\n      <td>0.193125</td>\n      <td>-0.717812</td>\n      <td>-0.804562</td>\n      <td>-0.008250</td>\n      <td>-0.009562</td>\n      <td>0.027188</td>\n      <td>-0.051063</td>\n      <td>-0.576125</td>\n      <td>0.692063</td>\n      <td>0.627938</td>\n      <td>-0.785875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.859687</td>\n      <td>0.531687</td>\n      <td>0.310500</td>\n      <td>-0.038938</td>\n      <td>-0.833000</td>\n      <td>0.475688</td>\n      <td>0.214625</td>\n      <td>-0.871188</td>\n      <td>-0.000250</td>\n      <td>-0.895750</td>\n      <td>-0.811813</td>\n      <td>0.244750</td>\n      <td>-0.182938</td>\n      <td>0.228562</td>\n      <td>0.386750</td>\n      <td>0.313188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.000000</td>\n      <td>-0.987500</td>\n      <td>-0.138437</td>\n      <td>-0.937500</td>\n      <td>-0.733625</td>\n      <td>-0.354875</td>\n      <td>0.047500</td>\n      <td>-0.998563</td>\n      <td>-0.616125</td>\n      <td>0.111375</td>\n      <td>0.332375</td>\n      <td>-0.601938</td>\n      <td>-1.000000</td>\n      <td>-0.900688</td>\n      <td>0.170063</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.869625</td>\n      <td>0.109812</td>\n      <td>0.074313</td>\n      <td>-0.647687</td>\n      <td>-0.667375</td>\n      <td>-0.701562</td>\n      <td>-0.093875</td>\n      <td>-0.848375</td>\n      <td>-1.000000</td>\n      <td>-0.911438</td>\n      <td>-0.075312</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.403062</td>\n      <td>-0.557000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.000000</td>\n      <td>0.025062</td>\n      <td>0.063687</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.238062</td>\n      <td>0.320750</td>\n      <td>-0.984812</td>\n      <td>-0.895563</td>\n      <td>-0.882187</td>\n      <td>-0.735687</td>\n      <td>-0.188812</td>\n      <td>-0.203000</td>\n      <td>0.169000</td>\n      <td>0.037375</td>\n      <td>-0.145812</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7286</th>\n      <td>-0.854437</td>\n      <td>0.637375</td>\n      <td>0.357000</td>\n      <td>-0.967375</td>\n      <td>-1.000000</td>\n      <td>-0.767750</td>\n      <td>0.365125</td>\n      <td>-0.996875</td>\n      <td>-0.955375</td>\n      <td>-0.309562</td>\n      <td>0.132625</td>\n      <td>-0.757437</td>\n      <td>-0.880563</td>\n      <td>0.320063</td>\n      <td>0.131625</td>\n      <td>-0.976750</td>\n    </tr>\n    <tr>\n      <th>7287</th>\n      <td>-0.981437</td>\n      <td>0.179000</td>\n      <td>-0.028625</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.686937</td>\n      <td>0.449500</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.681312</td>\n      <td>0.398062</td>\n      <td>-0.960938</td>\n      <td>-0.992063</td>\n      <td>0.413250</td>\n      <td>-0.019063</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>7288</th>\n      <td>-0.512062</td>\n      <td>0.561813</td>\n      <td>0.824500</td>\n      <td>-0.637750</td>\n      <td>-0.980313</td>\n      <td>-0.647375</td>\n      <td>0.697625</td>\n      <td>-0.761813</td>\n      <td>-0.863438</td>\n      <td>-0.600250</td>\n      <td>0.155438</td>\n      <td>-0.295813</td>\n      <td>-0.785125</td>\n      <td>0.599250</td>\n      <td>0.676125</td>\n      <td>-0.832250</td>\n    </tr>\n    <tr>\n      <th>7289</th>\n      <td>-0.897938</td>\n      <td>0.652687</td>\n      <td>0.769000</td>\n      <td>-0.689937</td>\n      <td>0.051688</td>\n      <td>0.787000</td>\n      <td>0.502938</td>\n      <td>0.386000</td>\n      <td>0.496375</td>\n      <td>0.126250</td>\n      <td>-0.066937</td>\n      <td>0.603812</td>\n      <td>-0.626812</td>\n      <td>0.627125</td>\n      <td>0.731625</td>\n      <td>-0.330000</td>\n    </tr>\n    <tr>\n      <th>7290</th>\n      <td>-1.000000</td>\n      <td>0.197563</td>\n      <td>-0.247125</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.300187</td>\n      <td>0.317125</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.378625</td>\n      <td>0.213813</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.011938</td>\n      <td>-0.309188</td>\n      <td>-1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>7291 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrainComprimido = comprimir(dataTrain)\n",
    "dataTrainComprimido"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5         6   \\\n0    -0.868688  0.056500 -0.001625 -0.641938 -0.152250 -0.787312  0.184125   \n1    -0.966688 -0.569750 -1.000000 -1.000000 -0.187875 -0.763562 -0.796687   \n2    -0.483062  0.198125  0.123875 -0.561312 -1.000000 -0.696688  0.269875   \n3    -0.992687 -0.595375 -1.000000 -1.000000 -0.011312 -0.623188 -0.505563   \n4    -1.000000 -0.238187 -0.378500 -1.000000 -0.222188 -0.406188 -1.000000   \n...        ...       ...       ...       ...       ...       ...       ...   \n2002 -1.000000  0.180188 -0.055812 -1.000000 -1.000000 -0.981250  0.283312   \n2003 -1.000000  0.063562  0.408312 -0.901750 -0.892313  0.577125  0.548500   \n2004 -0.810187 -0.005563 -0.743188 -1.000000 -0.096000 -0.138250  0.778250   \n2005 -0.624563  0.787875  0.270062 -0.873812  0.312312 -0.152375 -0.207500   \n2006 -1.000000 -0.462000 -0.149375 -1.000000 -1.000000 -0.161687 -0.173812   \n\n            7         8         9         10        11        12        13  \\\n0    -0.451750 -0.807500 -0.135188  0.297625 -1.000000 -1.000000 -0.922813   \n1    -0.183313  0.000500 -0.785813  0.180438  0.031688 -0.368125 -0.036375   \n2    -0.489875 -1.000000 -0.404500 -0.152937 -0.539875 -0.471187  0.135438   \n3    -0.006125  0.172937 -0.763313  0.045813 -0.019875 -0.626375 -0.320437   \n4    -1.000000  0.177125 -0.787312  0.076625  0.428437  0.231250  0.520563   \n...        ...       ...       ...       ...       ...       ...       ...   \n2002 -1.000000 -1.000000 -1.000000 -0.018750 -0.735563 -0.652750  0.177312   \n2003 -0.991187 -1.000000 -0.785375  0.246250 -1.000000 -1.000000 -0.592750   \n2004 -0.296687 -0.415937  0.480875 -0.358563 -1.000000 -1.000000  0.290500   \n2005  0.167500  0.440250 -0.197437  0.257563  0.159500 -0.500687  0.853250   \n2006 -1.000000 -1.000000 -0.063312 -0.279500 -1.000000 -1.000000 -0.535375   \n\n            14        15  \n0    -0.059500 -1.000000  \n1    -0.170687 -0.899500  \n2     0.294250 -0.472500  \n3    -0.358437 -0.920875  \n4     0.112063 -0.462875  \n...        ...       ...  \n2002  0.208250 -0.794000  \n2003 -0.196375 -1.000000  \n2004 -0.801813 -1.000000  \n2005  0.471125 -0.844000  \n2006 -0.127688 -1.000000  \n\n[2007 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.868688</td>\n      <td>0.056500</td>\n      <td>-0.001625</td>\n      <td>-0.641938</td>\n      <td>-0.152250</td>\n      <td>-0.787312</td>\n      <td>0.184125</td>\n      <td>-0.451750</td>\n      <td>-0.807500</td>\n      <td>-0.135188</td>\n      <td>0.297625</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.922813</td>\n      <td>-0.059500</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.966688</td>\n      <td>-0.569750</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.187875</td>\n      <td>-0.763562</td>\n      <td>-0.796687</td>\n      <td>-0.183313</td>\n      <td>0.000500</td>\n      <td>-0.785813</td>\n      <td>0.180438</td>\n      <td>0.031688</td>\n      <td>-0.368125</td>\n      <td>-0.036375</td>\n      <td>-0.170687</td>\n      <td>-0.899500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.483062</td>\n      <td>0.198125</td>\n      <td>0.123875</td>\n      <td>-0.561312</td>\n      <td>-1.000000</td>\n      <td>-0.696688</td>\n      <td>0.269875</td>\n      <td>-0.489875</td>\n      <td>-1.000000</td>\n      <td>-0.404500</td>\n      <td>-0.152937</td>\n      <td>-0.539875</td>\n      <td>-0.471187</td>\n      <td>0.135438</td>\n      <td>0.294250</td>\n      <td>-0.472500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.992687</td>\n      <td>-0.595375</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.011312</td>\n      <td>-0.623188</td>\n      <td>-0.505563</td>\n      <td>-0.006125</td>\n      <td>0.172937</td>\n      <td>-0.763313</td>\n      <td>0.045813</td>\n      <td>-0.019875</td>\n      <td>-0.626375</td>\n      <td>-0.320437</td>\n      <td>-0.358437</td>\n      <td>-0.920875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.000000</td>\n      <td>-0.238187</td>\n      <td>-0.378500</td>\n      <td>-1.000000</td>\n      <td>-0.222188</td>\n      <td>-0.406188</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.177125</td>\n      <td>-0.787312</td>\n      <td>0.076625</td>\n      <td>0.428437</td>\n      <td>0.231250</td>\n      <td>0.520563</td>\n      <td>0.112063</td>\n      <td>-0.462875</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2002</th>\n      <td>-1.000000</td>\n      <td>0.180188</td>\n      <td>-0.055812</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.981250</td>\n      <td>0.283312</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.018750</td>\n      <td>-0.735563</td>\n      <td>-0.652750</td>\n      <td>0.177312</td>\n      <td>0.208250</td>\n      <td>-0.794000</td>\n    </tr>\n    <tr>\n      <th>2003</th>\n      <td>-1.000000</td>\n      <td>0.063562</td>\n      <td>0.408312</td>\n      <td>-0.901750</td>\n      <td>-0.892313</td>\n      <td>0.577125</td>\n      <td>0.548500</td>\n      <td>-0.991187</td>\n      <td>-1.000000</td>\n      <td>-0.785375</td>\n      <td>0.246250</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.592750</td>\n      <td>-0.196375</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>2004</th>\n      <td>-0.810187</td>\n      <td>-0.005563</td>\n      <td>-0.743188</td>\n      <td>-1.000000</td>\n      <td>-0.096000</td>\n      <td>-0.138250</td>\n      <td>0.778250</td>\n      <td>-0.296687</td>\n      <td>-0.415937</td>\n      <td>0.480875</td>\n      <td>-0.358563</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.290500</td>\n      <td>-0.801813</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>-0.624563</td>\n      <td>0.787875</td>\n      <td>0.270062</td>\n      <td>-0.873812</td>\n      <td>0.312312</td>\n      <td>-0.152375</td>\n      <td>-0.207500</td>\n      <td>0.167500</td>\n      <td>0.440250</td>\n      <td>-0.197437</td>\n      <td>0.257563</td>\n      <td>0.159500</td>\n      <td>-0.500687</td>\n      <td>0.853250</td>\n      <td>0.471125</td>\n      <td>-0.844000</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>-1.000000</td>\n      <td>-0.462000</td>\n      <td>-0.149375</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.161687</td>\n      <td>-0.173812</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.063312</td>\n      <td>-0.279500</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.535375</td>\n      <td>-0.127688</td>\n      <td>-1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTestComprimido = comprimir(dataTest)\n",
    "dataTestComprimido"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[343   1   1   2   0   6   2   2   0   2]\n",
      " [  2 145   1   0   3   2   1   0   6   0]\n",
      " [  0   1 179   2  12   0   4   1   0   1]\n",
      " [  4   5   2 175   1   5   2   1   3   0]\n",
      " [  0   0   3   0 170   1   0   3   0   0]\n",
      " [  3   2   2   1   6 145   0   0   5   2]\n",
      " [  8   1   2   1   0   0 157   0   0   1]\n",
      " [  0   0   4   1   7   1   0 131   3   0]\n",
      " [  3  17   0   2   2   7   0   0 134   1]\n",
      " [  1   1   3   1   0   5   3   2   1 247]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9098156452416543\n",
      "\n",
      "Error Global:\n",
      "0.09018435475834574\n",
      "\n",
      "Precisión por categoría:\n",
      "       cero    cinco  cuatro       dos     nueve      ocho      seis  \\\n",
      "0  0.955432  0.90625   0.895  0.883838  0.960452  0.873494  0.923529   \n",
      "\n",
      "      siete      tres       uno  \n",
      "0  0.891156  0.807229  0.935606  \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Matriz de Confusión': array([[343,   1,   1,   2,   0,   6,   2,   2,   0,   2],\n        [  2, 145,   1,   0,   3,   2,   1,   0,   6,   0],\n        [  0,   1, 179,   2,  12,   0,   4,   1,   0,   1],\n        [  4,   5,   2, 175,   1,   5,   2,   1,   3,   0],\n        [  0,   0,   3,   0, 170,   1,   0,   3,   0,   0],\n        [  3,   2,   2,   1,   6, 145,   0,   0,   5,   2],\n        [  8,   1,   2,   1,   0,   0, 157,   0,   0,   1],\n        [  0,   0,   4,   1,   7,   1,   0, 131,   3,   0],\n        [  3,  17,   0,   2,   2,   7,   0,   0, 134,   1],\n        [  1,   1,   3,   1,   0,   5,   3,   2,   1, 247]]),\n 'Precisión Global': 0.9098156452416543,\n 'Error Global': 0.09018435475834574,\n 'Precisión por categoría':        cero    cinco  cuatro       dos     nueve      ocho      seis  \\\n 0  0.955432  0.90625   0.895  0.883838  0.960452  0.873494  0.923529   \n \n       siete      tres       uno  \n 0  0.891156  0.807229  0.935606  }"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloDataSinComprimir = MLPClassifier(hidden_layer_sizes =(250,100,50,25), max_iter = 50000, activation = 'relu', solver = 'adam',random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(predecir= \"Numero\",modelo=modeloDataSinComprimir, random_state=0, xtrain= dataTrainComprimido, xtest=dataTestComprimido, ytrain=ytrain, ytest=ytest)\n",
    "analisisModelo2.fit_predict_resultados(inyectado=ytrain.append(ytest), custom=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[316   1   0  10   1   8  15   0   1   7]\n",
      " [  5 120   2   4   3   3   4   0  17   2]\n",
      " [  2   1 163   5  20   0   3   2   1   3]\n",
      " [  9   3   1 171   1   2   1   1   5   4]\n",
      " [  0   0  20   1 136   4   0   9   1   6]\n",
      " [ 11   8   4   4   6  95   4   1   8  25]\n",
      " [ 15   1   0   4   0   0 147   0   3   0]\n",
      " [  0   0   9   0  15   4   0 115   1   3]\n",
      " [  8  17   2   9   2   5   1   4 116   2]\n",
      " [  0   1   6   2   0   3   5   5   0 242]]\n",
      "\n",
      "Precisión Global:\n",
      "0.807673143996014\n",
      "\n",
      "Error Global:\n",
      "0.19232685600398602\n",
      "\n",
      "Precisión por categoría:\n",
      "       cero  cinco  cuatro       dos     nueve      ocho      seis     siete  \\\n",
      "0  0.880223   0.75   0.815  0.863636  0.768362  0.572289  0.864706  0.782313   \n",
      "\n",
      "       tres       uno  \n",
      "0  0.698795  0.916667  \n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Matriz de Confusión': array([[316,   1,   0,  10,   1,   8,  15,   0,   1,   7],\n        [  5, 120,   2,   4,   3,   3,   4,   0,  17,   2],\n        [  2,   1, 163,   5,  20,   0,   3,   2,   1,   3],\n        [  9,   3,   1, 171,   1,   2,   1,   1,   5,   4],\n        [  0,   0,  20,   1, 136,   4,   0,   9,   1,   6],\n        [ 11,   8,   4,   4,   6,  95,   4,   1,   8,  25],\n        [ 15,   1,   0,   4,   0,   0, 147,   0,   3,   0],\n        [  0,   0,   9,   0,  15,   4,   0, 115,   1,   3],\n        [  8,  17,   2,   9,   2,   5,   1,   4, 116,   2],\n        [  0,   1,   6,   2,   0,   3,   5,   5,   0, 242]]),\n 'Precisión Global': 0.807673143996014,\n 'Error Global': 0.19232685600398602,\n 'Precisión por categoría':        cero  cinco  cuatro       dos     nueve      ocho      seis     siete  \\\n 0  0.880223   0.75   0.815  0.863636  0.768362  0.572289  0.864706  0.782313   \n \n        tres       uno  \n 0  0.698795  0.916667  }"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrainComprimido = comprimir(dataTrain, filtradoPorMayor=True)\n",
    "dataTestComprimido = comprimir(dataTest, filtradoPorMayor=True)\n",
    "\n",
    "modeloDataSinComprimir = MLPClassifier(hidden_layer_sizes =(250,100,50,25), max_iter = 50000, activation = 'relu', solver = 'adam',random_state=0)\n",
    "analisisModelo2 = Analisis_Predictivo(predecir= \"Numero\",modelo=modeloDataSinComprimir, random_state=0, xtrain= dataTrainComprimido, xtest=dataTestComprimido, ytrain=ytrain, ytest=ytest)\n",
    "analisisModelo2.fit_predict_resultados(inyectado=ytrain.append(ytest), custom=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "dataTrainComprimido = comprimir(dataTrain, filtradoPorMayor=True)\n",
    "dataTestComprimido = comprimir(dataTest, filtradoPorMayor=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "         0      1    2      3      4    5      6      7      8      9      10  \\\n0    -1.000  1.000  1.0 -1.000  0.909  1.0  0.996  0.867  1.000  1.000  1.000   \n1     0.392  1.000  1.0  1.000  0.366  1.0  1.000  0.653  1.000  0.214  0.993   \n2    -1.000 -0.888  1.0 -0.189  0.988  1.0  1.000 -0.977  1.000  1.000  1.000   \n3     0.409  1.000  1.0  1.000  1.000  1.0  1.000  0.695 -1.000  0.061  1.000   \n4    -1.000  1.000  1.0 -1.000 -1.000  1.0  1.000 -0.757  0.337  0.224  0.998   \n...     ...    ...  ...    ...    ...  ...    ...    ...    ...    ...    ...   \n7286  0.167  1.000  1.0 -0.586 -1.000  1.0  1.000 -0.950 -0.318  1.000  1.000   \n7287 -0.713  1.000  1.0 -1.000 -1.000  1.0  1.000 -1.000 -1.000  0.970  1.000   \n7288  1.000  1.000  1.0  0.992 -0.685  1.0  1.000  0.566  0.754  1.000  1.000   \n7289  0.353  1.000  1.0  1.000  1.000  1.0  1.000  1.000  1.000  1.000  1.000   \n7290 -1.000  1.000  1.0 -1.000 -1.000  1.0  1.000 -1.000 -1.000  1.000  1.000   \n\n         11     12     13     14     15  \n0     1.000  1.000  1.000  1.000  0.864  \n1     1.000  1.000  1.000  1.000  1.000  \n2     1.000 -1.000  0.046  1.000 -1.000  \n3    -1.000 -1.000  1.000  0.958 -1.000  \n4     1.000  1.000  1.000  1.000  1.000  \n...     ...    ...    ...    ...    ...  \n7286  0.219  0.233  1.000  1.000 -0.628  \n7287 -0.589 -0.885  1.000  1.000 -1.000  \n7288  1.000  1.000  1.000  1.000  0.860  \n7289  1.000  1.000  1.000  1.000  1.000  \n7290 -1.000 -1.000  1.000  1.000 -1.000  \n\n[7291 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>0.909</td>\n      <td>1.0</td>\n      <td>0.996</td>\n      <td>0.867</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.864</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.392</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.366</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.653</td>\n      <td>1.000</td>\n      <td>0.214</td>\n      <td>0.993</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.000</td>\n      <td>-0.888</td>\n      <td>1.0</td>\n      <td>-0.189</td>\n      <td>0.988</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>-0.977</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>0.046</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.409</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.695</td>\n      <td>-1.000</td>\n      <td>0.061</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>0.958</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>-0.757</td>\n      <td>0.337</td>\n      <td>0.224</td>\n      <td>0.998</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7286</th>\n      <td>0.167</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-0.586</td>\n      <td>-1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>-0.950</td>\n      <td>-0.318</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.219</td>\n      <td>0.233</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-0.628</td>\n    </tr>\n    <tr>\n      <th>7287</th>\n      <td>-0.713</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>0.970</td>\n      <td>1.000</td>\n      <td>-0.589</td>\n      <td>-0.885</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>7288</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>0.992</td>\n      <td>-0.685</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.566</td>\n      <td>0.754</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.860</td>\n    </tr>\n    <tr>\n      <th>7289</th>\n      <td>0.353</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>7290</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>7291 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrainComprimido"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "         0      1     2      3     4      5      6      7      8      9    10  \\\n0     0.810  1.000  1.00  1.000  1.00  0.248  1.000  1.000  0.955  1.000  1.0   \n1    -0.467  0.963 -1.00 -1.000  1.00  0.960  0.808  1.000  1.000  0.820  1.0   \n2     1.000  1.000  1.00  1.000 -1.00  1.000  1.000  1.000 -1.000  1.000  1.0   \n3    -0.883  0.999 -1.00 -1.000  1.00  1.000  1.000  1.000  1.000  0.179  1.0   \n4    -1.000  1.000  1.00 -1.000  1.00  1.000 -1.000 -1.000  1.000  0.999  1.0   \n...     ...    ...   ...    ...   ...    ...    ...    ...    ...    ...  ...   \n2002 -1.000  1.000  1.00 -1.000 -1.00 -0.797  1.000 -1.000 -1.000 -1.000  1.0   \n2003 -1.000  1.000  1.00 -0.175 -0.07  1.000  1.000 -0.859 -1.000  0.396  1.0   \n2004  0.768  1.000  0.82 -1.000  1.00  1.000  1.000  1.000  1.000  1.000  1.0   \n2005  1.000  1.000  1.00  0.645  1.00  1.000  1.000  1.000  1.000  1.000  1.0   \n2006 -1.000  1.000  1.00 -1.000 -1.00  1.000  1.000 -1.000 -1.000  1.000  1.0   \n\n         11     12     13    14     15  \n0    -1.000 -1.000 -0.424  1.00 -1.000  \n1     1.000  0.980  1.000  1.00  0.250  \n2     1.000  1.000  1.000  1.00  1.000  \n3     1.000  1.000  1.000  1.00  0.177  \n4     1.000  1.000  1.000  1.00  1.000  \n...     ...    ...    ...   ...    ...  \n2002  0.984  0.957  1.000  1.00  0.899  \n2003 -1.000 -1.000  0.871  1.00 -1.000  \n2004 -1.000 -1.000  1.000  0.06 -1.000  \n2005  1.000  1.000  1.000  1.00  0.753  \n2006 -1.000 -1.000  1.000  1.00 -1.000  \n\n[2007 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.810</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.248</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.955</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-0.424</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.467</td>\n      <td>0.963</td>\n      <td>-1.00</td>\n      <td>-1.000</td>\n      <td>1.00</td>\n      <td>0.960</td>\n      <td>0.808</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.820</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>0.980</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>-1.00</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.883</td>\n      <td>0.999</td>\n      <td>-1.00</td>\n      <td>-1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.179</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.177</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>0.999</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2002</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n      <td>-1.00</td>\n      <td>-0.797</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.0</td>\n      <td>0.984</td>\n      <td>0.957</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.899</td>\n    </tr>\n    <tr>\n      <th>2003</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>-0.175</td>\n      <td>-0.07</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-0.859</td>\n      <td>-1.000</td>\n      <td>0.396</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>0.871</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>2004</th>\n      <td>0.768</td>\n      <td>1.000</td>\n      <td>0.82</td>\n      <td>-1.000</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>0.06</td>\n      <td>-1.000</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.645</td>\n      <td>1.00</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>0.753</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n      <td>-1.00</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.0</td>\n      <td>-1.000</td>\n      <td>-1.000</td>\n      <td>1.000</td>\n      <td>1.00</td>\n      <td>-1.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTestComprimido\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}